{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sithar_text_generation_nlp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zGGKRH87Ark",
        "outputId": "235b6b3c-50da-497a-d679-25eeac350a85"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxGtZZMt7MAa",
        "outputId": "f7930332-960b-45e9-9e18-a8542bd6b1d1"
      },
      "source": [
        "#A package for easing return of multiple values\n",
        "!nvidia-smi\n",
        "#Create and update Microsoft Word .docx files.\n",
        "!pip install python-docx\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import docx\n",
        "import re"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 18 10:29:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.7/dist-packages (0.8.11)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ8YERJW8DvE"
      },
      "source": [
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFRtSRsfGBmA"
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M5g5bUi9BNV"
      },
      "source": [
        "text1 = (open(\"/content/drive/My Drive/sithara_songs_data.txt\").read())\n",
        "text1=text.lower()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLIX-HjY-MgS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3573684c-6292-4d38-b087-815df96a8e02"
      },
      "source": [
        "data = text1.split('\\n') #split the text with respect to new line\n",
        "data[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ethu mazhayilum - udaharanam sujatha'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtzxfWJUCBQu",
        "outputId": "e1a2943a-6556-4ad8-fc1b-a92d4d3ebfc6"
      },
      "source": [
        "len(data)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmx3cE7sFBzV"
      },
      "source": [
        "The total number of lines in our data is 1370"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "B_iMbSkHCLCA",
        "outputId": "cbc6f929-c51f-4012-944f-29631372c8f3"
      },
      "source": [
        "data = \" \".join(data)  #join all the lines to form a long string \n",
        "data[:200]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ethu mazhayilum - udaharanam sujatha  ethu mazhayilaalumoru thirinaalam raavu pakaloru pole viriyana thaaram novu karipukayoothi erivirakaay meenaveyilodu koode vazhi palatheri paadamezhuthiya jeevaka'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKFqZr4qCrB2",
        "outputId": "2ca53334-f700-40f7-8805-06c0e41b37a1"
      },
      "source": [
        "def clean_text(data):  #to remove all the punctuation mark and special characters\n",
        "  tokens = data.split()  #split the data according to space character\n",
        "  table = str.maketrans('', '', string.punctuation) #delete the punctations ie., the maketrans() has 3 arguments 1st the characters that needs to be replaced with,2 nd \n",
        "                                                    # what to replace and 3rd the characters to be deleted.Here, we delete the punctuation\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  #The translate() method returns a string where some specified characters are replaced with the character described in a dictionary, or in a mapping table.                                                  \n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  #The isalpha() method returns True if all the characters are alphabet letters (a-z)\n",
        "  tokens = [word.lower() for word in tokens] #to lower case\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ethu', 'mazhayilum', 'udaharanam', 'sujatha', 'ethu', 'mazhayilaalumoru', 'thirinaalam', 'raavu', 'pakaloru', 'pole', 'viriyana', 'thaaram', 'novu', 'karipukayoothi', 'erivirakaay', 'meenaveyilodu', 'koode', 'vazhi', 'palatheri', 'paadamezhuthiya', 'jeevakathayude', 'ediloru', 'lipiyaayi', 'ere', 'vijanatha', 'choozhum', 'irulilum', 'aashayathu', 'kalayaathe', 'chiri', 'thooki', 'mukilaayi', 'nee', 'niravaalin', 'kara', 'thedi', 'ethu', 'mazhayilaalumoru', 'thirinaalam', 'raavu', 'pakaloru', 'pole', 'viriyana', 'thaaram', 'hridayamulayum', 'murivu', 'mozhiyaal', 'moodi', 'samayamani', 'pol']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTNxaOu2C0t5",
        "outputId": "7104a11a-babd-4c27-f464-3a1115a8e192"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4030"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNyLN3f5JKpg"
      },
      "source": [
        "The total number of words are 4030"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9y0q0mWJCtS",
        "outputId": "08ff6794-291d-4a80-ac04-fdb15896c9c4"
      },
      "source": [
        "len(set(tokens))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L4jj7IzJQSE"
      },
      "source": [
        "The total number of unique words are 2035"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlnIrpONJIUt",
        "outputId": "17687fd9-2c36-4ba8-c402-c332e690b7cb"
      },
      "source": [
        "length = 10 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  \n",
        "\n",
        "print(len(lines))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dEBm2g0ZKdjF",
        "outputId": "276f2a52-c1aa-4318-a786-88d30ccdb90f"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ethu mazhayilum udaharanam sujatha ethu mazhayilaalumoru thirinaalam raavu pakaloru pole viriyana'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-vInKscNKoh1",
        "outputId": "42228bca-f1fe-4604-9770-4b904a26e2a4"
      },
      "source": [
        "tokens[10]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'viriyana'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SyX42mKK5w4"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D-hQDVxLNGm"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiB53SfgL2a3"
      },
      "source": [
        "sequences contains a list of integer values created by tokenizer. Each line in sequences has 11 words. Now we will split each line such that the first 10 words are in X and the last word is in y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYh3rW1sLnvm",
        "outputId": "c00d0d0e-e84a-4b0b-859e-732774cadc1c"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 364, 2035,  367,  366,  364,  365,  363,  217,  362,   19])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-AbLAMLrGt"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gon4GaOMJjw"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v6159UEMOqs",
        "outputId": "95eaeac9-18bb-4227-9644-9f9e815a67cb"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZMtiFK3MR_7",
        "outputId": "c5f4cb80-fbb7-4a05-f267-88195707c048"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 50)            101800    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 10, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2036)              205636    \n",
            "=================================================================\n",
            "Total params: 458,336\n",
            "Trainable params: 458,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiKVX2F_MkO9"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zopmJBfaMtdf",
        "outputId": "45f1b45d-7cad-4c3b-9747-4df3be3bd833"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 34s 11ms/step - loss: 7.6179 - accuracy: 0.0059\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 12ms/step - loss: 7.5536 - accuracy: 0.0155\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 7.1772 - accuracy: 0.0160\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 6.9938 - accuracy: 0.0132\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.8662 - accuracy: 0.0213\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.6938 - accuracy: 0.0236\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.5582 - accuracy: 0.0219\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.4686 - accuracy: 0.0241\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.4073 - accuracy: 0.0231\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.2986 - accuracy: 0.0291\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.2333 - accuracy: 0.0261\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.1596 - accuracy: 0.0334\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 6.0902 - accuracy: 0.0255\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.9810 - accuracy: 0.0296\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.9352 - accuracy: 0.0338\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.7970 - accuracy: 0.0362\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.7125 - accuracy: 0.0317\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.5795 - accuracy: 0.0406\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 5.4256 - accuracy: 0.0488\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.2798 - accuracy: 0.0433\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 5.1193 - accuracy: 0.0534\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.9176 - accuracy: 0.0613\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.8052 - accuracy: 0.0697\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.6816 - accuracy: 0.0719\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.5563 - accuracy: 0.0887\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.4243 - accuracy: 0.0877\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.3662 - accuracy: 0.0957\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.1848 - accuracy: 0.1090\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 4.0578 - accuracy: 0.1212\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.9760 - accuracy: 0.1361\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.8967 - accuracy: 0.1387\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.7878 - accuracy: 0.1459\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 8ms/step - loss: 3.6436 - accuracy: 0.1584\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.5252 - accuracy: 0.1825\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.4291 - accuracy: 0.1959\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.3341 - accuracy: 0.2035\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.2682 - accuracy: 0.2168\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.1614 - accuracy: 0.2325\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 3.1218 - accuracy: 0.2325\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.9928 - accuracy: 0.2650\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.9352 - accuracy: 0.2762\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.8571 - accuracy: 0.2837\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.7412 - accuracy: 0.3240\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.6386 - accuracy: 0.3460\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.5464 - accuracy: 0.3662\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.4885 - accuracy: 0.3798\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.3976 - accuracy: 0.4023\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.3281 - accuracy: 0.4114\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.2503 - accuracy: 0.4315\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.2163 - accuracy: 0.4349\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.1207 - accuracy: 0.4569\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 2.0214 - accuracy: 0.4880\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.9397 - accuracy: 0.5260\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.9255 - accuracy: 0.5297\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.8833 - accuracy: 0.5246\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.8129 - accuracy: 0.5464\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.7591 - accuracy: 0.5476\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.7139 - accuracy: 0.5754\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.6320 - accuracy: 0.5895\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.5786 - accuracy: 0.6066\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.5375 - accuracy: 0.6246\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.4710 - accuracy: 0.6373\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.4300 - accuracy: 0.6494\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.3713 - accuracy: 0.6709\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1.3400 - accuracy: 0.6685\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.3197 - accuracy: 0.6726\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.3216 - accuracy: 0.6612\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.2177 - accuracy: 0.7013\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.1917 - accuracy: 0.7098\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.1602 - accuracy: 0.7075\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0904 - accuracy: 0.7310\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0823 - accuracy: 0.7346\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0309 - accuracy: 0.7509\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 1.0215 - accuracy: 0.7527\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.9612 - accuracy: 0.7643\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.9208 - accuracy: 0.7691\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.9096 - accuracy: 0.7750\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8885 - accuracy: 0.7842\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8661 - accuracy: 0.7880\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8286 - accuracy: 0.8035\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.8119 - accuracy: 0.7957\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7712 - accuracy: 0.8159\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7662 - accuracy: 0.8081\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7440 - accuracy: 0.8098\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.7339 - accuracy: 0.8228\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7401 - accuracy: 0.8072\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.7269 - accuracy: 0.8246\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.8293\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.6622 - accuracy: 0.8361\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.6303 - accuracy: 0.8433\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5979 - accuracy: 0.8566\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5784 - accuracy: 0.8622\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5597 - accuracy: 0.8655\n",
            "Epoch 94/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5545 - accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.5441 - accuracy: 0.8682\n",
            "Epoch 96/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5509 - accuracy: 0.8606\n",
            "Epoch 97/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.8681\n",
            "Epoch 98/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4954 - accuracy: 0.8793\n",
            "Epoch 99/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4857 - accuracy: 0.8729\n",
            "Epoch 100/100\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4575 - accuracy: 0.8919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff31010b1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3aaDaE96M0I-",
        "outputId": "fb2ac868-444d-4904-cf68-dc5ba423c856"
      },
      "source": [
        "seed_text=lines[12]\n",
        "seed_text"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'novu karipukayoothi erivirakaay meenaveyilodu koode vazhi palatheri paadamezhuthiya jeevakathayude ediloru lipiyaayi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5qzIdpkNKxm"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "iIdZRkOpN7DH",
        "outputId": "85641159-62c8-474b-fb67-775cfcdbdfdf"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 5)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ere vijanatha choozhum irulilum aashayathu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtwW0WJAN9OZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}